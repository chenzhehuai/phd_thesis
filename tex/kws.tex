

\chapter{非传统识别任务的序列建模}

语音识别是一种序列预测问题，在语音识别中一个独有并且有趣的自然现象是声学序列和语言学序列的长度可变性。
序列模型正是被提出用来解决两个序列之间的关联性。
依据序列的不同定义方式，目前有两种不同的序列鉴别性训练方法，一种针对生成式序列模型 (GSM) 比如上文介绍的HMM以及其相应的深度学习系统；另一种则针对鉴别式序列模型 (DSM) ，比如 CTC 或者 encoder-decoder 模型。 
在这些序列模型中，除了需要研究如何将各种基于深度学习的模型方法应用到逐帧分类当中，使用序列级的鉴别性训练准则来强化模型的序列分类能力，也被证明是取得业界最好的大词汇连续语音识别系统的关键。


序列建模方法通常只在训练LVCSR模型时进行使用，但针对其他非传统识别任务的序列建模研究并不充分，这包括：关键词检测任务和多说话人重叠语音信号识别任务等。这类任务仍然是序列预测问题，但是却没有合适的训练准则和相应的设计，来充分优化分类器的序列建模能力。因此这些领域近几年的进展主要仍然来自于深度学习本身所带来的更好的逐帧分类能力。

本章节将针对上面所说的两类任务探讨序列建模的方案，使之更加通用。
我们提出了针对固定或者非固定关键词的关键词检测系统的序列鉴别性训练框架。我们系统地研究了序列生成模型和序列鉴别模型情况下的序列鉴别性训练
通过引入词语无关的音素词图或非关键词的 {\em blank} 单元来构建竞争性搜索空间，我们在声学KWS系统上提出了一系列有效并且高效的序列鉴别性训练方法。实验表明我们提出的方法取得了一致并且显著的改善。这些测试包括固定关键词或非固定关键词的关键词检测任务，比较的基线是逐帧的深度学习声学KWS模型方法。
%
另一方面，在多说话人重叠语音信号识别任务中，本章节通过联合优化，迁移学习，序列鉴别性训练等方式，改善了原来语音分离、信号增强和语音识别的联合训练系统。


\section{关键词检测的序列建模和标签同步解码}
\label{chap:kws}

%KWS
%method categorized, what we discuss

关键词检测(KWS)是语言识别最主要的应用之一，它的目标是得到一个高准确度和高效率的识别器，用于检测特定的一些关键词在语音中的出现。
KWS可以被用于声学数据挖掘~\cite{zhou2005data}, 低资源的音频检索~\cite{shen2009comparison}, 
语料库检索~\cite{garofolo2000trec} 和 唤醒词识别~\cite{chen2014small}. 本文主要考虑后两种应用。

我们在第\ref{chap:intro-kws-dec}章节对关键词检测技术的分类和相应的声学建模方法进行了总结。
%
在声学关键词检测中，模型通常是进行逐帧分类的。目前研究趋势包括两方面：应用一个较强的逐帧分类器，比如深度学习模型，使最终系统带来性能提升~\cite{chen2014small,sainath2015convolutional}。 其次，语音识别本身是一个序列分类问题，传统的GMM-HMM系统在使用序列级准则，序列鉴别性训练时，往往能带来显著性能提升，比如discriminatively trained sub-word verification function~\cite{sukkar1996vocabulary}, minimum classification error (MCE)~\cite{sandness2000keyword} 和 performance-related discriminative training~\cite{keshet2009discriminative}。
在上述的鉴别性训练中，对对识别可能性的建模，即完整的搜索空间的建模是成功的关键。但是，在 KWS中，由关键词所定义的领域内搜索空间要显著小于领域外的搜索空间。因此领域外的搜索空间通常还需要特定的建模单元进行建模。
对领域外的搜素空间建模并不容易直接得到的问题限制了序列鉴别性训练在关键词检测中的广泛应用。
特别是在非固定关键词的关键词检测, 所以可能的竞争可能性通常无法被穷举，同时这种可能性的产生过程在使用LVCSR框架进行的时候~\cite{povey2005discriminative}非常耗时。 
%combination of both hasn't been carefully 

%Neural networks (NNs) for speech recognition are typically trained to classify individual frames based on a cross-entropy criterion (section 2.1).
在这篇文章中，我们为深度学习的 声学非固定关键词的关键词检测设计了相应的序列鉴别性训练方法。关于如何对序列概率进行定义，可分为序列条件似然度和序列后验概率，这包括两种序列模型： {\em 生成式序列模型} (GSM)，比如HMM, 和 {\em 鉴别式序列模型} (DSM)，比如 CTC。
对于GSM，序列鉴别性训练需要在序列上使用贝叶斯公式来通过序列条件似然度得到后验概率；而DSM则可以直接使用序列后验概率。

对这两种框架，竞争可能性的建模都是核心难题。
本章节提出两种方法来解决这一问题：隐性使用音素或半词单元的语言模型来建模，或者显性加入非关键词的标签。
%proposed KWS 
%Both frameworks are improved in the paper. 
在HMM中，受到近期一些研究中使用特点音素语言模型来对LVCSR的搜索空间进行建模的启发~\cite{povey2016purely,chen2006advances},  我们提出使用这种音素语言模型来对关键词的完整搜索空间进行建模。
为了加强关键词的鉴别能力，在关键词出现时候它们的梯度可以被增强。除此之外，许多神经网络结构和鉴别性训练准则也进行了详细比较。
在CTC中，非关键词建模单元被直接引入到建模当中。具体来说，加入之后的CTC模型搜索空间包括了关键词，音素边界 ($\tt blank$) 和词边界 ($\tt wb$)。 
最后我们基于前面章节介绍的LSD算法提出了一种高效的后处理算法，以解决音素混淆建模的问题。

本章节的主要贡献包括：
i) 针对生成式序列模型和鉴别式序列模型的序列鉴别性训练的第一个系统研究工作
ii) 提出了一些新颖的办法来构建声学KWS的竞争可能性，以用于鉴别性训练。这些方法显著提升了关键词检测系统的性能。
iii) 基于 LSD框架提出了高效的后处理方法，以便对音素混淆性进行建模。



\subsection{关键词检测中传统序列建模方法的缺陷}

序列建模方法在语音识别中的应用如第~\ref{Sec:seq-tr-review}章所述。
而在声学KWS方法中，只有关键词序列被定义，而非关键词的竞争序列还未知。针对生成式序列模型 (GSM) ，基于似然度比值的可能性测试框架~\cite{sukkar1996utterance} 被提出以进行鉴别性训练，这里对其他竞争序列的似然度进行了惩罚。而这部分被惩罚的似然度使用两种单元进行建模： $\tt filler$ 模型, 建模非关键词的$p(\mathbf{O}_u|\Phi)$, 建模错误识别词的 $p(\mathbf{O}_u|\Psi)$ 。 与公式~(\ref{equ:lvcsr-mmi})相比，关键词序列的  $p(\mathbf{O}_u|\mathbf{W}_u)$ 可以被忽略，而对数边缘概率则被定义如下，
\begin{equation}
\label{equ:wbmve-po}
\begin{split}
\log p(\mathbf{O}_u)=\left\{\frac{1}{2}[\log p(\mathbf{O}_u|\Psi)^\lambda + \log p(\mathbf{O}_u|\Phi)^\lambda]\right\}^{1/\lambda}
%y_{ut}(s^{(r)}_{ut})
\end{split}
\end{equation}
这里的序列竞争可能序列 $\mathbf{W}$ 是由N-best序列得到的。
%In~\cite{sukkar1996vocabulary},
在这些方法中，人工加入的非关键词单元并不能进行很好的建模，原因是发音和声学的不同并没有办法完全囊括在一个建模单元当中。除此之外，该方法也没有对关键词和非关键词之间的上下文进行建模。另外由N-best得到竞争序列也并不重复。最后，该类方法也无法应用到非固定关键词的关键词检测中。

另一方面，对于鉴别式序列模型 (DSM)，在词级CTC~\cite{fernandez2007application}中, 
虽然它是一个序列级准则，但是并没有对非关键词部分进行建模。因此该准则改善了关键词之间的鉴别性，但是没有改善关键词和非关键词之间的鉴别性。



\subsection{基于HMM的关键词检测的序列鉴别性训练}
\label{Sec:kws-disc-proposed}

如前面的章节~\ref{Sec:sgm-sdt-intro}所述，将基于HMM的KWS使用序列鉴别性训练进行改善的主要难度在于如何得到词级别的可靠竞争序列估计。
受到之前研究中使用一个裁剪过的音素语言模型来代替词图在鉴别性训练中的应用的启发(称为 {\em 无词图鉴别性训练} (LF-MMI)~\cite{povey2016purely,chen2006advances}), 我们提出了一种通用的序列鉴别性训练框架，并针对非固定关键词的关键词检测任务。
这里的关键词序列由音素声学模型进行建模。相应我们就使用音素的语言模型来构建一个完整的搜索空间 ，使之包含关键词和非关键词的竞争序列。

\subsubsection{模型训练}
\label{Sec:lfmmi-train}

在所提出的音素声学模型中， (\ref{equ:lvcsr-mmi}) 被转换为 (\ref{equ:kws-mmi}) 并表示为 $\tt{LF\text{-}MMI}$。
公式中 $\mathbf{L}$ 是音素序列。 $\mathbf{L}_u$ 是标注标签序列。
$p(\mathbf{O}_u|\mathbf{L})$ 和 $p(\mathbf{O}_u|\mathbf{L}_u)$ 由公式~(\ref{equ:hmm-model_2})得到。 


该方法与传统鉴别性训练不同之处在于： 
\begin{itemize}
\item 在分母式子中所使用的标注序列 $\mathbf{L}_u$ 存在多种候选路径，这些候选路径来自于标注软对齐中对标签在一定窗宽内的左右帧移。这里将所有可能的对齐路径都存储在分子词图中。
\item 模拟搜索空间的分母语言模型 $P(\mathbf{L})$, $P(\mathbf{L}_u)$是使用一个在训练标注文本中训练得到的音素语言模型。
\item 一个专用的HMM拓扑结构被专门提出，它包含有两个HMM状态。其中状态${\bf q}_2$ 用于模拟CTC中的$\tt blank$ 建模单元，同时其他状态来模拟输出标签单元。这里的不同之处在于每个 tri-phone都维护一个它专有的$\tt blank$建模。
\item 输出帧率被降低了3倍。
\end{itemize}


%iv) the cross-entropy regularization is applied with moderately larger weight in the cross-entropy. The reason is that the sub-word level language model is unavailable in test stage. Empirically the model should balance between sequence level and frame level criteria.
%regu is similar but MTL-ce  


%model unit, hmm topo, state binding
为了更好地将 $\tt{LF\text{-}MMI}$ 应用到关键词检测当中，我们进行了如下改进：
i) 我们使用音素而不是tri-phone作为建模单元。
% to improve model inference efficiency. 
首先是在测试阶段，效率将会得到改善；其次是这样会使得后文将讨论的 $\tt filler$ 构建显著简化。
ii) HMM的拓扑结构如图~\ref{fig:hmm-topo}(d-e)所示进行了修改,
本文将图\ref{fig:hmm-topo}（d-e）所示的几种改进的HMM拓扑结构应用在了GSM中。具体来讲，在图\ref{fig:hmm-topo}（c）中，每个CD音素都有独立的blank状态，称为CD音素blank (CD phone blank)。为减少模型单元的数量并进一步加快算法速度，将中心音素相同的blank状态绑定在一起，称为音素级blank (phone blank)；最后如果绑定所有的blank状态则称作全局blank (global blank)。此外，鉴于标签延迟带来的性能改进\cite{amodei2015deep}，图\ref{fig:hmm-topo}（d）中提出HMM-PB模型的延迟标签变种，即HMM-BP。也就是说，模型在确定性标签输出之前输出混淆输出blank。另外，作为对CTC的完整模拟，图\ref{fig:hmm-topo}（e）中提出了HMM-BPB，允许在标签输出前后都存在blank。我们的初步实验结果表明，这两种类型的blank展现出了不同的功能。因此没有将它们绑定在一起。而输出标签单元后面的所有blank则都被绑定在了一起，以减少所需的模型单元数量。
在实验部分我们将详细比较这些拓扑结构~\ref{Sec:exp-model-arch}。

%similarlly b-mmi
为了对模型的鉴别性做进一步改善，一系列其他的序列鉴别性训练准则也在KWS的框架下进行了研究。 
首先，我们对序列中出现错误的部分进行了增强~\cite{povey2008boosted}，称为增强的$\tt{ LF\text{-}MMI}$, $\tt{ LF\text{-}bMMI}$。
\begin{equation}
\label{equ:kws-bmmi}
\begin{split}
\mathcal{F}_{\tt{LF\text{-}bMMI}}
%=- \sum_{u} \log \frac {p(\mathbf{O}_u|\mathbf{S}_u)^{\kappa}P(\mathbf{W}_u)}{\sum_{\mathbf{W}} p(\mathbf{O}_u|\mathbf{S})^{\kappa}P(\mathbf{W})}  
=\sum_{u} \log \frac {\sum_{\mathbf{L}_u} p(\mathbf{O}_u|\mathbf{L}_u)^{\kappa}P(\mathbf{L}_u)}{\sum_{\mathbf{L}} p(\mathbf{O}_u|\mathbf{L})^{\kappa}P(\mathbf{L})e^{-b\ \mathop{\max}_{\mathbf{L}_u} A(\mathbf{L},\mathbf{L}_u)}}  
\end{split}
\end{equation}
公式中 $A(\mathbf{L},\mathbf{L}_u)$ 表示逐个状态的准确度，通过比较序列和标注序列而得到。
$b$ 是增强参数。
由于 $\mathbf{L}_u$ 在分母中应用时是一个软对齐结果，因此增强量被选择为使用最佳准确度来获得。
%sMBR  
另一种鉴别性训练框架尝试最小化预期错误~\cite{gibson2006hypothesis}。无词图的minimum
Bayes risk ($\tt{LF\text{-}sMBR}$) 也在本章节中进行了研究。

\begin{equation}
\label{equ:kws-smbr}
\begin{split}
\mathcal{F}_{\tt{LF\text{-}sMBR}}
%=- \sum_{u} \log \frac {p(\mathbf{O}_u|\mathbf{S}_u)^{\kappa}P(\mathbf{W}_u)}{\sum_{\mathbf{W}} p(\mathbf{O}_u|\mathbf{S})^{\kappa}P(\mathbf{W})}  
=\sum_{u}  \frac {\sum_{\mathbf{L}} p(\mathbf{O}_u|\mathbf{L})^{\kappa}P(\mathbf{L})\mathop{\max}_{\mathbf{L}_u} A(\mathbf{L},\mathbf{L}_u)}{\sum_{\mathbf{L}} p(\mathbf{O}_u|\mathbf{L})^{\kappa}P(\mathbf{L})}  
\end{split}
\end{equation}

%Besides, varieties of neural network architectures and discriminative training criteria are compared.

  %NU-b-mmi
    %%how to get NU weight
这里所提出的序列鉴别性训练方法也可以被拓展到固定关键词的关键词检测任务中。为了增强针对特定关键词的区分度，我们可以把关键词相关的梯度进行加权。我们采用将逐帧的非一致性权重加入到损失函数中的方法，类似于\cite{meng2016non}在MCE中的做法。这里的关键点是要增强针对关键词的误唤醒或者未唤醒的情况。
%The non-uniform 序列鉴别性训练 idea proposed here can be applied in both Equation (\ref{equ:kws-mmi}), (\ref{equ:kws-bmmi}) and (\ref{equ:kws-smbr}). 
比如在LF-MMI中可以进行如下修改，得到非一致性LF-MMI ($\tt{NU\text{-}LF\text{-}MMI}$):
%\alpha(t)
\begin{equation}
\label{equ:kws-nummi}
\begin{split}
\frac{\partial \mathcal{F}_{\tt{NU\text{-}LF\text{-}MMI}}}{\partial\log p({\bf o}_{ut}|s)}
%=- \sum_{u} \log \frac {p(\mathbf{O}_u|\mathbf{S}_u)^{\kappa}P(\mathbf{W}_u)}{\sum_{\mathbf{W}} p(\mathbf{O}_u|\mathbf{S})^{\kappa}P(\mathbf{W})}  
=\frac{\partial \mathcal{F}_{\tt{LF\text{-}MMI}}}{\partial\log p({\bf o}_{ut}|s)}\cdot  \ell(t,u)
\end{split}
\end{equation}
公式中 $s$ 表示建模单元, $p({\bf o}_{ut}|s)$ 是真经网络在状态$s$ 时间 $t$ 句子 $u$上的输出。
$\ell(t,u)$ 是求导后针对导数的权重方程，它给定了时间 $t$ 和句子 $u$。 $\ell(t,u)$可以定义如下：
\begin{equation}
\label{equ:deriv-weight}
\ell(t,u)=
\begin{cases}
\mathop{\min(\alpha,\beta)}& r_{ut}\in \mathbf{K}\ \land\ i_{ut}\in \mathbf{K}\\
\alpha& r_{ut}\in \mathbf{K}\ \land\ i_{ut}\notin \mathbf{K}\\
\beta& i_{ut}\in \mathbf{K}\ \land\ r_{ut}\notin \mathbf{K}\\
1& others
\end{cases}
\end{equation}
公式中 $\mathbf{K}$ 是所有的关键词序列。 $r_{ut}$   是音素级的标注序列， $i_{ut}$ 是相应的推理搜索序列。 $\alpha$ 和 $\beta$为相应的增强参数 (它们都大于 $1$) ，它们依次针对未唤醒和误唤醒。对于公式(\ref{equ:deriv-weight})的第一种例子, $\mathop{\min(\alpha,\beta)}$ 被使用，原因是模型已经能够预测出相应的关键词。 $\ell(t,u)$ 可以由LF-MMI的种子模型得到。
% and the post-processing method.

%post processing
\subsubsection{后处理}
\label{Sec:post-process}

在这项工作中，我们采用后验平滑和基于$\tt filler$的后处理方式。

\begin{itemize}
  \item 后验平滑
\end{itemize}
后验平滑的目的是将噪声后验值简单地滤除掉。该方法第一次由~\cite{chen2014small}提出，下面我们仅罗列主要公式，具体讨论详见~\cite{chen2018kws}。

\begin{equation}
\label{equ:post-smooth-conf}
\begin{split}
P'(s'|{\bf o}_{ut'})=\mathcal{N}_1\left (\mathbf{P}(s|{\bf o}_{ut})^{(s=s',\ t\in [t'-\frac{1}{2}\mathrm w_{s},t'+\frac{1}{2}\mathrm w_{s}])}\right ) 
%\mathbf{P}(s|\mathbf{O}_u)_{t-\frac{1}{2}\mathrm w_{s}}^{t+\frac{1}{2}\mathrm w_{s}}
\end{split}
\end{equation}
\begin{equation}
\label{equ:post-smooth-conf2}
\begin{split}
P''(s'|{\bf o}_{ut'})=\mathcal{N}_2\left (\mathbf{P}'(s|{\bf o}_{ut})^{(s=s',\ t\in [t'-\mathrm w_{m}+1,t'])}\right ) 
\end{split}
\end{equation}
\begin{equation}
\label{equ:post-smooth-conf3}
\begin{split}
\mathcal C(\mathbf{k})^{(t')}=\mathcal{N}_3\left (\mathbf{P}''(s|{\bf o}_{ut})^{(s\in \mathbf{k},t=t')}\right ) 
\end{split}
\end{equation}
公式中 $P(s'|{\bf o}_{ut'})$, $P'(s'|{\bf o}_{ut'})$ 和 $P''(s'|{\bf o}_{ut'})$ 是三种不同的归一化函数。  $\mathbf{P}(s|{\bf o}_{ut})^{(s\in \mathbf{s},t\in\mathbf{t})}$, $\mathbf{P}'(s|{\bf o}_{ut})^{(s\in \mathbf{s},t\in\mathbf{t})}$ 和 $\mathbf{P}''(s|{\bf o}_{ut})^{(s\in \mathbf{s},t\in\mathbf{t})}$ 是三种平滑后的状态序列。$\mathcal{N}_1(\cdot)$, $\mathcal{N}_2(\cdot)$ 和 $\mathcal{N}_3(\cdot)$ 是三种不同的平滑函数。在工作~\cite{chen2014small}中,  算数平均，最大值，集合平均，分别被采用。

\begin{itemize}
  \item {$\tt filler$解码}
\end{itemize}

$\tt filler$解码方法用于建模前面我们所讨论的领域外的搜索空间。在这项工作中的搜索空间如图~\ref{fig:filler-graph}所示。

\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=\textwidth]{figure/filler-graph.png}
    \bicaption[fig:filler-graph]{}{基于 $\tt filler$ 解码的搜索空间结构图}{Fig}{$\tt filler$ based decoding search space}
\end{figure}


它包含了两个部分：领域内搜索空间和领域外搜索空间。前者由关键词的子序列建模得到，如图~\ref{fig:filler-graph}中的音素序列。 $\tt filler$ 子网络用于对领域外的搜索空间进行建模。$\tt filler$ 子网络是由所有的音素自环组成的。

\subsection{基于CTC的关键词检测的标签同步解码}
\label{Sec:kws-ctc}

\subsubsection{模型训练}
\label{Sec:modeltrain}

如前面章节\ref{Sec:sdm-sdt-intro}所述，序列鉴别性训练的关键之处是竞争序列的建模。
%criteria \& model unit
在本文中，我们研究了两种方向：词语建模和音素建模的CTC关键词检测模型。

为了更好地建模词级CTC模型的竞争序列，这里针对非关键词引入了新的建模单元。
类似于传统的声学KWS方法，代表非关键词的$\tt filler$被引入。在训练阶段, $\tt filler$ 则取代所有标注中的非关键词。

%word boundary modelling
另一个方向是针对音素级模型，我们进行修改的动机是：
i) 任何音素序列，也包括非关键部分，都可以由音素模型来进行建模。
ii) 使得声学模型容易做到与关键词无关，应用于非固定关键词的关键词检测任务。
%
除此之外，我们在词语边界处引入了 $\tt wb$ 单元~\cite{zhuang-is2016}。 在 音素 CTC 中 $\tt wb$ 和 $\tt blank$ 被分别作为词和音素的边界进行建模。区分这样的边界区段不仅可以改善泛化能力，而且也对后面将介绍的后处理有帮助。

这里针对引入的建模单元，公式修改如下：
\begin{equation}
\label{equ:ctc-kw}
\begin{split}
P(\mathbf{L}_u|\mathbf{O}_u)=P(\mathbf{L}_u'|\mathbf{O}_u)_{\mathbf{L}_u' = \mathcal{D}(\mathbf{L}_u)}
\end{split}
\end{equation}
$\mathcal{D}$ 是标签的映射函数。 $\mathcal{D}$ 针对词级或者音素级CTC具有不同的定义。
\begin{equation}
\label{equ:ctc-d}
\begin{split}
\mathcal{D}_{\tt{word}}:\mathbb{L}  \mapsto \mathbb{L}  \cup \{{\tt filler}\}\\
\mathcal{D}_{\tt{sub-word}}:\mathbb{L}  \mapsto \mathbb{L}  \cup \{{\tt wb}\}
\end{split}
\end{equation}
经过修改之后，在词级或者音素级建模中，搜索空间都将包含关键词，非关键词，音素边界和词边界。

\subsubsection{后处理}
\label{Sec:post-process-ctc}

我们进一步基于最小编辑距离（MED）提出了一个针对CTC推理搜索分布的后处理方法，以便引入音素的混淆性先验知识，增强模型性能。这项工作受到\cite{chaudhari2007improvements}启发, 这里基于CTC词图和MED算法~\cite{7736093}l来针对音素引入混淆建模。 

%which generates a sub-word lattice on the basis of the output probability distribution of CTC and then performs search.  
图~\ref{fig:med-framework} 给出了在音素CTC中使用MED算法的框架。再一句音频中，关键词出现于CTC词图的概率是用三种编辑距离的概率相乘得到的，它们包括插入，删除，替换。每一种操作的概率由MED算法决定。现实中，每个音素在CTC的建模中性能可能各不相同，因此需要进一步采用音素的先验来设计每个音素的阈值，这部分可以通过预先统计得到~\cite{zhuang-is2016}。

\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=\textwidth]{figure/kws-framework.eps}
    \bicaption[fig:med-framework]{MED方法框架}{MED方法框架。这里使用音素CTC作为例子}{Fig}{The framework of MED based method. Phone based CTC is taken as an example.}
\end{figure}

\subsubsection{序列鉴别性训练在HMM和CTC框架中的比较}
\label{Sec:disc-and-ctc}

本文中， 序列鉴别性训练被分为两种序列模型而进行: 生成式序列模型 和 鉴别式序列模型。在开始实验部分之前，我们先对两种做法进行一些综合比较：

\begin{itemize}
  \item {\em 生成和鉴别式序列模型}。 在HMM中，需要采用贝叶斯公式将序列状态转移概率和深度学习所估计的后验概率结合起来。在CTC中，给定特征序列后的标签序列的后验概率则直接由深度学习模型进行建模。
  \item {\em 序列建模}。 通过引入 $\tt{blank}$ 到每一帧分解后的建模当中，CTC隐性地对标签进行了序列建模。在HMM中，标签序列被显性地被N元语言模型进行限制和共同建模。
  在计算序列的后验概率时，两种框架都使用了前后向算法。
  \item {\em 混淆区段}. $\tt{blank}$ 原先是提供给CTC进行两个标签之间的混淆区段的建模的。类似的结构也可以如图~\ref{fig:hmm-topo}(c-e)所示在HMM中使用。除了拓扑结构的不同， $\tt blank$ 的粒度在HMM和 CTC中也是初始不同的。
  \item {\em 竞争序列建模}. 在词级CTC中，非关键词元素显示地由建模单元进行建模，即 $\tt filler$ 和 $\tt wb$。 在HMM中，我们采用音素单元对这些竞争序列进行隐性的建模。同时一个音素级的语言模型给出了音素搜索空间的建模效果。 %phone+explicit lm prior
  %\item {\em Discriminative training}. CTC directly models the sequence level posterior probability. The sequence discrimination is implied in the model. For GSM, 序列鉴别性训练 employs maximum a posteriori (MAP) criterion. The discrimination between the correct label sequence and competing hypotheses is modeled by the occupancy probability of the former versus that of the latter.
\end{itemize}


\section{鲁棒语音识别中的深度序列建模}
\label{chap:intro2-pit}

近年来随着深度学习发展，将语音信号的增强和语音识别进行联合训练成为一种新的趋势。这样做的好处包括：更好地利用序列信息进行训练；对模型前后模块进行联合调优以解决模型失配问题。在多说话人重叠语音信号识别任务中，本章节通过联合优化，迁移学习，序列鉴别性训练等方式，改善了原来语音分离、信号增强和语音识别的联合训练系统。

\subsection{排列不变性训练及其在鸡尾酒会问题中应用}
\label{chap:intro2-pit-pit}

鸡尾酒会问题~\cite{cherry1953some,bregman1994auditory}是指多说话人重叠语音信号的识别问题，该问题在会议转录系统，自动音视频字幕生成等任务中非常重要，因为语音信号的重叠是常见的一种信号现象。同时该问题也是语音识别中最困难的问题之一~\cite{wang2006computational,cooke2010monaural,du2014speech,weng2015deep}。在鸡尾酒会问题中，最困难的是无监督鸡尾酒会问题。这种情况下，多人同时说话，而只有一个麦克风系统进行收音，同时系统不提前具有说话人信息，需要泛化到没有见过说话人情况。


排列不变性训练是解决该问题的一种有效框架~\cite{yu2017recognizing}。该框架首先通过选取最小的当前排列下的推理搜索误差来决定当前最优排列，而后依据该排列来使用其相应的误差对模型进行反向误差传递的梯度更新。
在鸡尾酒会的语音识别问题中，原先的信号分离误差被替换为针对语音识别结果的交叉熵误差。
\begin{equation}
\label{equ:ce-pit}
\begin{split}
%\mathcal{J}_{\text{CE-PIT}}=\sum_u \frac{1}{N}\min_{s'\in \mathbf{S}} \sum_{n\in[1,N]} CE(\mathbf{L}_{un}^{(s')},\mathbf{L}_{un}^{(r)})
\mathcal{J}_{\text{CE-PIT}}=\sum_u \min_{s'\in \mathbf{S}} \sum_t \frac{1}{N} \sum_{n\in[1,N]} CE({l}_{utn}^{(s')},{l}_{utn}^{(r)})
\end{split}
\end{equation}
公式中 $\mathbf{S}$ 表示所有针对标注和推理搜索序列的可能排列组合。
%inference representations
${l}_{utn}^{(s')}$ 为在排列 $s'$ ，第$t$ 帧，第 $u$ 个句子上的第 $n$个推理搜索结果。 ${l}_{utn}^{(r)}$ 是相应的从干净语音信号进行对齐算法得到的标注序列~\cite{woodland1994large}.
%review of PIT-ASR formulation
PIT-ASR 准则~\cite{yu2017recognizing} 优雅地将语音信号的分离，说话人跟踪，语音识别都融合在一个系统里，如图~\ref{fig:modules}(a)所示。

在接下来章节中，我们提出将无监督的鸡尾酒会问题拆分为三个子问题，并逐一进行初始化：
逐帧的语音信号的分离，说话人跟踪，语音识别，如图~\ref{fig:sys-fr}所示。 
每个模块通过在上一个模块基础上添加若干层神经网络而得到，由此逐渐解决更加困难问题。
在初始化之后，各模块组合起来进行联合调优。我们提出了两种联合训练思路：针对自身的迁移学习，多输出的序列鉴别性训练；除了这些工作之外，我们还提出了一系列对建模过程的改善，参见~\cite{chen2018progressive}。


\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=0.7\textwidth]{figure/modules.pdf}
    \bicaption[fig:modules]{PIT-ASR 联合训练与模块化初始化和逐步联合训练比较}{PIT-ASR 联合训练与模块化初始化和逐步联合训练比较。 点划线框表示可以学习的模型参数。点线框表示可以学习的并且是共享的模型参数。}{Fig}{The comparison between joint training, modular initialization, and progressive joint training.}
\end{figure}


\subsection{基于迁移学习的排列不变性训练}
\label{chap:intro2-pit-ts}

迁移学习（教师-学生训练）被引入到这个问题中，以便使用平行干净语料来改善目标领域的混合语音识别系统。在这一框架中，学生是指该多说话人语音识别系统。它工作在目标领域，即混合语音信号的数据上，并尝试得到每个说话人相应的话语内容。这里教师模型输入源领域，即干净语音信号，并尝试分别对每个说话人得到相应推理搜索序列。



\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=1.1\textwidth]{figure/sys-framework.png}
    \bicaption[fig:sys-fr]{逐步联合训练模型系统框架}{迁移学习模型系统训练框架。
    \cite{yu2017recognizing}中提出的结构由虚线框部分表示，其用于推理搜索出每个说话人的语音信号的信息。该结构被模块化（三个实线框）并作逐一增量预训练。针对自身的迁移学习和多输出序列鉴别性训练在模块初始化后神经网络上进行。}{Fig}{The progressive joint training model framework.}
\end{figure}


这一针对自身的迁移学习将最小化混合语音信号的模型和干净语音信号的模型输出分布之间的KL散度（KLD）。
这一KL散度被定义为句子层面干净语音信号的和混合语音信号的推理搜索分布之间的PIT准则，如下所示，
\begin{equation}
\label{equ:kld-opt}
\begin{split}
\mathcal{J}_{\text{KLD-PIT}}=\sum_u \min_{s'\in \mathbf{S}} \sum_t \frac{1}{N} \sum_{n\in[1,N]} \\
KLD(P({l}_{utn}^{(c)}|\mathbf{O}_{un}^{(r)}),P({l}_{utn}^{(s')}|\mathbf{O}_{u}^{(m)}))
\end{split}
\end{equation}
该式中，每个 $KLD(\cdot)$ 对的计算过程和经典领域自适应方式迁移学习公式相似。值得注意的一点是，当该方法被应用到如图~\ref{fig:joint-tr}所示的结构时，语音识别模块可以直接使用教师模型进行初始化。
% fixed [jasha] I think this sentence captures the meaning of the commented-out text below it.
% [t-zhehch] but we should define $P({l}_{utn}^{(s')}|\mathbf{O}_{u}^{(m)})$$ and $P({l}_{utn}^{(c)}|\mathbf{O}_{un}^{(r)})$
%Specifically, the clean speech model fine-tunes its parameters with other joint-trained modules in overlapped speech,  , to fit its own distribution in the simultaneous clean speech, i.e. clean speech model distribution .

图~\ref{fig:tr-curve}给出了多种训练方法在验证集上的学习曲线比较。从图中可以看出，本章节所提出的方法具有更好初始点和最终的收敛点。这些都得益于本章节方法使得神经网络的学习任务更简单，最终收敛效果相应得到了提升。


\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=\textwidth]{figure/joint-tr.pdf}
    \bicaption[fig:joint-tr]{基于迁移学习逐步联合训练方法}{基于迁移学习逐步联合训练方法。点划线框表示可以学习的参数，点线框表示可以学习并且是共享的模型参数。}{Fig}{The self-transfer learning based model framework.}
\end{figure}



\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=\textwidth]{figure/tr-curve.pdf}
    \bicaption[fig:tr-curve]{原始联合训练和所提出的方法在验证集上学习曲线比较}{原始联合训练和所提出的方法在验证集上学习曲线比较。在图中，联合训练，逐步联合训练，基于迁移学习逐步联合训练被分别表示为Joint Model,  Pro. Joint Model 和 Pro. Joint Model + Transf. 图中每个epoch包含24小时训练数据。}{Fig}{The learning curve comparison of naive joint training and the proposed methods. }
\end{figure}

\subsection{基于序列鉴别性训练的排列不变性训练}
\label{chap:intro2-pit-dt}

本章节我们提出了一种传统鉴别性训练技术变种，它在进行鉴别性训练的同时，也抑制输出通道上说话人跟踪错误。

语音识别是一种序列分类和预测问题。因此在单输出语音识别中，序列级的准则将有助于改善系统性能。
而在鸡尾酒会问题中，对于单通道多说话人混叠语音识别系统，则又包含了说话人跟踪问题，也属于序列级问题。因此序列鉴别性准则将有助于这样序列分类问题。
在单输出语音识别中，我们使用如下公式对序列后验概率进行建模，

%ASR can be formulated as a {\em{maximum a posterior}} (MAP) decision process to integrate sequence level criteria to the training of the acoustic model. 
  
\begin{equation}
\label{equ:single-mbr}
\begin{split}
P(\mathbf{L}_u|\mathbf{O}_u)=\frac {p(\mathbf{O}_u|\mathbf{L}_u)P(\mathbf{L}_u)}{p(\mathbf{O}_u)}  
%y_{ut}(s^{(r)}_{ut})
\end{split}
\end{equation}
公式中$\mathbf{L}_u$ 是句子 $u$的词序列。 $P(\mathbf{L}_u)$ 是语言模型概率。
$p(\mathbf{O}_u|\mathbf{L}_u)$ 是相应声学模型概率。
 $p(\mathbf{O}_u)$ 是针对特征序列 $\mathbf{O}_u$观察概率进行建模的边缘概率，它等于所有可能的识别序列的概率求和。

通常来说，语言模型搜索空间是通过训练集语料来估计得到。之后在该搜索空间上计算相应的序列准则。 
由于之前训练搜索空间的语料未出现词语交换问题，因此搜索空间也不包含这些建模。在这样的搜索空间上训练将导致对搜索空间估计不准确，而最终的推测序列中将会增加较多词语交换错误。我们提出了一系列方法以解决该问题，这里的想法是将词语交换错误添加到搜索空间中，由此减轻问题。
\begin{equation}
\label{equ:lf-dc-mmi}
\begin{split}
\mathcal{J}_{\tt{LF\text{-}DC\text{-}MMI}}
%=- \sum_{u} \log \frac {p(\mathbf{O}_u|\mathbf{S}_u)^{\kappa}P(\mathbf{L}_u)}{\sum_{\mathbf{L}} p(\mathbf{O}_u|\mathbf{S})^{\kappa}P(\mathbf{L})}  
=\sum_{u} \log  [ \frac {\sum_{\mathbf{L}_u} p(\mathbf{O}_u|\mathbf{L}_u)^{\kappa}P(\mathbf{L}_u)}{(\ \sum_{\mathbf{L}} p(\mathbf{O}_u|\mathbf{L})^{\kappa}P(\mathbf{L})\ )^{1-\lambda} } 
\cdot \\ 
\frac{1} {(\ {\sum_{\mathbf{L}_{\hat{u}}}} p(\mathbf{O}_u|{\mathbf{L}_{\hat{u}}})^{\kappa}P({\mathbf{L}_{\hat{u}}})\ )^\lambda}
 ]
\end{split}
\end{equation}
在公式~\ref{equ:lf-dc-mmi}中, 除当前优化的输出序列之外其他输出序列表示为 $\mathbf{L}_{\hat{u}}$。公式中添加了一项插值系数 $\lambda$。该部分额外式子最后被加入到分母优化当中。通过这样的方法，在优化目标序列的同时，也同时抑制了跨信道的词语交换错误。


\section{实验结果}
\label{chap:kws-exp}


本部分的关键词检测实验将分别在HMM和CTC框架下进行，我们对两种框架分别进行了序列鉴别性训练实验。
非固定关键词的关键词检测 (语料库检索 任务), 和固定关键词的关键词检测（唤醒词识别 任务）都在实验部分进行了考察。所有实验都是在声学KWS上进行。


多说话人重叠语音信号识别任务在Switchboard数据集的人工混叠集合上进行，我们以排列不变性训练作为该任务下的基线系统，并分别验证了前文所提出的联合优化，迁移学习，序列鉴别性训练等方式。

%\subsection{非固定关键词的关键词检测 task}
%\label{Sec:}
\subsection{英文语料库检索任务}
\label{Sec:exp-sp-docu-detri}

\subsubsection{实验配置}
\label{Sec:exp-sp-docu-detri-setup}

Wall Street Journal (WSJ0)数据集的一个说话人独立的5k词表数据集 \cite{garofalo1993continous} 被用于评估基于 CTC词图的KWS。 至少出现过5词的词或短语被随机挑选出来作为关键词。总计有50个关键词。

由于WSJ0数据集比较小，同时关键词出现次数较少，因此我们在HMM和CTC中都使用音素作为建模单元，以提高泛化能力，而词作为建模单元将在下章中进行。
输出的音素由CMU 发音词典得到。24维对数filter-bank系数及其第一和第二阶导数组成了10ms固定帧率的特征序列。
HMM模型的配置与 \cite{povey2016purely}中相似，但使用了更好的参数如表~\ref{tab:model-discri} 和表 \ref{tab:perf-all}所示。 我们估计了三元的音素语言模型用于LF-MMI的训练。
%zhc00@qingdao:/aifs/users/zhc00/works/lfmmi/wsj/sjtu$ fstinfo exp/chain/tdnn_sjtu_mono_2n_mhmm1c.NSN.0.1.32.12_nd/phone_lm.fst
我们使用$\alpha=2.5$ 和 $\beta=2.5$ 作为 NU-LF-bMMI的参数。
CTC模型的配置详见 \cite{7736093}。我们使用单向 每层384节点的两层LSTM 进行实验，其带有 128 个节点的映射层。
%The LSTM network was initiated using cross-entropy criterion and then trained using CTC criterion.
%For performance comparison, conventional {\em keyword-filler} DNN-HMM was also trained as baselines. DNN has an 11-frame context window with 5 extended frames on the left and right. %Both HMM systems have 1689 clustered triphone states. 
所有声学模型都使用 Kaldi进行训练~\cite{povey2011kaldi}.
 {\em 等错误率} (EER) 用来度量上面两种测试下的错误率，该指标反映了无唤醒和未唤醒错误的均值。越低的EER表示越好的模型性能。
我们也绘出了receiver operating characteristic (ROC) 曲线，以总结实验结果。
在基于$\tt filler$ 的解码中, 表示为 {\em{kw-filler}}, 而EER是由扫描修改filler权重而得到的。
后验概率平滑，表示为 {\em{smooth}}， 和 CTC MED后处理方法, 表示为 {\em{MED}}, 都是通过\cite{7736093}中提出的固定阈值方法得到的。
\begin{equation}
\label{equ:eer-thres}
\begin{split}
\mathcal T_{EER}(\mathbf{k})=\mathcal T_0+\mathcal T(\mathbf{k})
\end{split}
\end{equation}
公式中 $\mathcal T(\mathbf{k})$ 是针对关键词 $\mathbf{k}$的阈值估计。 $\mathcal T_0$ 在所有关键词中共享，并通过调节它得到EER结果。

{\em 实时率} (RTF), 解码时间与音频时长的百分比, 被作为对整体速度的衡量指标。越低的RTF表示速度越好。
在测试阶段，我们使用的CPU型号为
{\em{Intel(R) Xeon(R) CPU E5-2690 v2 @ 3.00 GHz}}. 
%The ASR decoder used in kw-filler systems is an internal optimized WFST decoder. 
%Clustered cross-word tri-phone HMMs were used as baselines\footnote{Since the KWS task in this paper concerns unrestricted keyword vocabulary, keyword-specific approaches such as \cite{chen2014small} are not appropriate baselines.}.
%A GMM system with 40 Gaussian mixtures and a DNN system of 4 hidden layers with 512 nodes per layer were built.
%The acoustic feature for GMM is 13-dimensional cepstral mean normalized MFCC coefficients  with their first and second order derivatives.

\subsubsection{HMM和CTC模型训练}
\label{Sec:exp-model-arch}
\begin{itemize}
\item {生成式序列模型}
\end{itemize}

本章节比较了不同的声学模型配置。基于HMM的序列鉴别性训练结果见表~\ref{tab:model-discri}。
%model unit (context), hmm topo, MTL. 
这里的所有模型都是通过公式 (\ref{equ:kws-mmi})中的LF-MMI模型进行训练得到的，同时这里使用了KW-Filler的后处理方法。 
\begin{table}[thbp!]
  \caption{\label{tab:model-discri} {\it 基于HMM的序列鉴别性训练的模型框架}}
   \vspace{2em}
  %\vspace{1mm}
  \centerline{
    \begin{tabular}{c | c | c |c |c||c}
      \hline
      \multicolumn{1}{c|}{NN Model} &
      \multicolumn{1}{c|}{Context } &
      \multicolumn{1}{c|}{\# Param.} &
      \multicolumn{1}{c|}{CEW} &
      \multicolumn{1}{c||}{HMM} &
      \multicolumn{1}{c}{EER} \\
      \hline \hline
      \multirow{1}{0.1\columnwidth}{BLSTM}&\multirow{1}{0.05\columnwidth}{CD}& 0.60M & 0.1& \multirow{1}{0.05\columnwidth}{PB} & 3.3  
       \\
      \hline
      \hline
      \multirow{7}{0.1\columnwidth}{\textbf{TDNN}}&\multirow{1}{0.05\columnwidth}{CD} & 0.54M& 0.1&\multirow{1}{0.05\columnwidth}{PB}  & 3.3  
       \\
      \cline{2-6}
      &\multirow{6}{0.05\columnwidth}{\textbf{CI}}& \multirow{6}{0.1\columnwidth}{\textbf{0.51M}} & 0.1&\multirow{4}{0.05\columnwidth}{PB}  & 3.3  \\
      \cline{4-4}\cline{6-6}
      &&& 0.4&  & 3.2  \\
      \cline{4-4}\cline{6-6}
      &&&\textbf{0.7}& & 3.1  \\
      \cline{4-4}\cline{6-6}
      &&&1.0&& 3.2  \\
      \cline{4-5}\cline{6-6}
      &&&\multirow{2}{0.04\columnwidth}{0.7} &\multirow{1}{0.05\columnwidth}{\textbf{BP}}  & 3.0  \\
      \cline{5-5}\cline{6-6}
      &&&&\multirow{1}{0.05\columnwidth}{BPB}  & 3.0  \\
      \hline
    \end{tabular}
  }
\end{table}

我们首先对深度学习模型的架构进行了研究。第一二行比较了双向 LSTM (BLSTM) 和 时延神经网络(TDNN)在同等参数下的性能。 BLSTM 包含两层前后向各80个节点的LSTM网络。映射层包含30个节点。 CD TDNN 包含7层100个节点， CI TDNN 包含7层150个节点。结果显示了相似的EER性能。我们相信这是由于： i) 在KWS中，作为模型推理搜索所需要的上下文并不需要很长，TDNN已经足够来针对这样的应用。 ii) 由于KWS模型的参数较少，因此限制了BLSTM模型的性能。在接下来的实验中，我们只讨论TDNN，原因是同等性能情况下它的速度更快~\footnote{我们暂未比较LSTM。近期的一些研究发现TDNN和LSTM可以被结合并取得更好的性能~\cite{tdnnlstm}}。
其次， 模型的建模单元在第二和三行中进行了比较。 tri-phone状态模型, 表示为上下文相关系统 (CD), 与单音素状态模型,表示为上下文无关系统 (CI)进行了比较。
CD模型基于三状态的从左到右的triphone 模型，包括 1536个绑定状态 (senones). 
%zhc00@qingdao:/aifs/users/zhc00/works/lfmmi/wsj/sjtu$ nnet3-info exp/nnet3/nnet_tdnn_a_tiny_smbr/final.mdl
它们的性能接近于 CI 模型。 %Besides the reason previously discussed, the stronger sequence level modeling effect in LF-MMI is another fold~\cite{povey2016purely}. 
第三，对于交叉熵规范化权重，表示为 CEW, 在第三到第六行中进行了调整。
结果显示 $0.7$ 可以得到最优结果，该值被使用在了后续的实验中。该值比LVCSR中偏大，原因是音素语言模型在测试阶段并不存在，这与LVCSR不同，因此训练过程仍在鉴别性训练和交叉熵准则之间权衡。
最终我们使用的拓扑结构如图~\ref{fig:hmm-topo} 
%
所示在第五，七和八行进行了比较。我们提出的BP，BPB比PB\cite{povey2016purely}轻微改善。 
但是在50个关键词上的显著性检验显示结果并不充分 ($\alpha=0.05$, $p=0.18$)。 
性能改善的原因可能为标签延迟所带来的改善~\cite{amodei2015deep}，但需要后续更多的研究。 
%And the reason of the similar performance between BP and BPB is also that the label delay makes the confusion span of model inference,  B, mainly exist  before the label output, while the duration of certain pronunciation in the model unit is modeled by the self-loop in the label output HMM state,  P. 
由于BP的搜索空间比 BPB 小，而性能相似，因此后续实验使用BP。

\begin{table}[thbp!]
  \caption{\label{tab:criteria-discri} {\it 基于HMM的鉴别性训练的准则比较}}
  \vspace{1mm}
  \centerline{
    \begin{tabular}{c ||c}
      \hline
      \multicolumn{1}{c||}{鉴别性训练准则 } &
      \multicolumn{1}{c}{EER} \\
      \hline \hline
%      CE& 4.0 \\
%      \hline\hline
%      CE+sMBR & 3.5 \\
%      \hline
      LF-MMI &3.0 \\
      \textbf{LF-bMMI} &2.9 \\
      LF-sMBR &2.9 \\
      \hline\hline
      NU-LF-bMMI &2.7 \\
      \hline
    \end{tabular} 
  }
\end{table}
第~\ref{Sec:lfmmi-train}章给出了不同准则，在表~\ref{tab:criteria-discri}中进行了比较。 % criteria: CE, mmi, b-mmi, smbr, NU-mmi. 
%The setup is as previously discussed, and 
这里使用 kw-filler进行后处理。 LF-bMMI 和 LF-sMBR 都显示好于 LF-MMI的性能，这与 LVCSR中的结论一致~\cite{vesely2013sequence}. 由于 LF-bMMI 训练快于 LF-sMBR 而性能相似，因此它被用在了后续实验中。
除此之外，NU-LF-bMMI 也参与了比较。这是一个固定关键词的关键词检测算法。在这种情况下，50个预先定义的关键词在训练阶段进行了使用，以加强关键词相关的梯度权重。经过训练之后，声学模型与关键词相关。
NU-LF-bMMI 带来额外的性能提升，而另一方面传统的固定关键词的关键词检测方法~\cite{chen2014small}并不能泛化这样的关键词无关训练集。后续NU-LF-bMMI 并不继续参与该数据集的比较，因为它与关键词无关算法并不可比。

%all tdnn CI kw-filler

\begin{itemize}
\item {鉴别式序列模型}
\end{itemize} 

在音素CTC中，引入的$\tt wb$ 建模单元在表~\ref{tab:wb}中进行了比较。对于少于6个音素的关键词被认为是短关键词，其余的为长关键词。因此可以将关键词集分成两部分分别检查他们的模型性能。
在短和长关键词中$\tt wb$都可以带来性能提升。长关键词的性能一致地优于短关键词，原因是短关键词的音素序列更可能是其他关键词的子集，造成了混淆和误唤醒率；$\tt wb$的引入缓解了这个问题。

 \begin{table}[h]
 \caption{\label{tab:wb} {\it 音素CTC在是否包含 $\tt wb$ 时的模型性能}}
 \vspace{2em}
  \centerline
  {
\begin{tabular}{cc||c}
\hline 
Keyword Length & wb & EER \tabularnewline
\hline 
\hline 
\multirow{2}*{short} & $\times$ & 9.0 \tabularnewline
& $\bm{\surd}$ & 4.5 \tabularnewline
\hline\hline
\multirow{2}*{long} & $\times$ & 3.1 \tabularnewline
 & $\bm{\surd}$ & 1.8 \tabularnewline
\hline 
\end{tabular}
 }
%\vspace{2mm}
\end{table}

\subsubsection{后处理和速度分析}
\label{Sec:exp-post-process}

不同的针对HMM和CTC的后处理算法在本节中进行了检查。值得注意的是，本部分是非固定关键词的关键词检测任务，因此音素被用来构建关键词序列。

\begin{table}[thbp!]
  \caption{\label{tab:post-discri} {\it  序列鉴别性训练系统的后处理}}
  \vspace{2em} 
  %\vspace{1mm}
  \centerline{
    \begin{tabular}{c |c||cc}
      \hline
      \multicolumn{1}{c|}{Model (Crit.) } &
      \multicolumn{1}{c||}{Post} &
      \multicolumn{1}{c}{EER} &
      \multicolumn{1}{c}{RTF}\\
      \hline \hline
      HMM&  smooth &9.8&0.008 \\
      (LF-bMMI)& \textbf{kw-filler} &2.9&0.028\\
      \hline\hline
      %\multirow{2}{0.2\columnwidth}{NU-LF-bMMI}& smooth& 8.5  \\
      %& kw-filler&2.7\\
      %\hline\hline
      %0.026+0.012
       & smooth& 11.4  &0.026\\
     CTC & \textbf{kw-filler}&3.2&0.038\\
      & MED & 3.6 &0.031\\
      \hline
    \end{tabular}
  }
\end{table}
如表~\ref{tab:post-discri} 所示，在 LF-bMMI 和 CTC中，后验概率平滑方法会得到比 kw-filler显著差的结果。但是由于它的速度优势，该方法可以作为实际的前处理，滤除一些容易判断的样本，以减少语料库检索同的计算量。
在 CTC中我们比较了所提出的 MED 算法。
它显示了明显比kw-filler更差一些的性能，但效率较高。该方法将会在后续章节中进一步检验。
kw-filler系统可以使用前述的标签同步解码算法进行进一步速度优化，因此 CTC 可以得到比LF-bMMI更快的速度。最终系统CTC比LF-bMMI慢则源于其使用的LSTM速度比TDNN在LF-bMMI中的使用更慢。

\subsubsection{性能比较}
\label{Sec:exp-perf-comp}

最后，我们将性能和速度的比较总结在表~\ref{tab:perf-all}中。 同时我们绘制出了 ROC 曲线如图~\ref{fig:roc}, 其中越低的曲线结果越好。
其中所有的系统都使用kw-filler作为后处理方法。

\begin{table}[thbp!]
  \caption{\label{tab:perf-all} {\it  非固定关键词的关键词检测中的性能和速度比较}}
  \vspace{2em} 
  %\vspace{1mm}
  \centerline{
    \begin{tabular}{c | c | c |c ||cc}
      \hline
      \multicolumn{1}{c|}{Model } &
      \multicolumn{1}{c|}{Context } &
      \multicolumn{1}{c|}{\# Param. } &
      \multicolumn{1}{c||}{Criterion} &
%      \multicolumn{1}{c||}{Post} &
      \multicolumn{1}{c}{EER} &
      \multicolumn{1}{c}{RTF} \\
      \hline \hline
      %\multirow{1}{0.05\columnwidth}{dnn}&\multirow{1}{0.05\columnwidth}{CD}&\multirow{1}{0.05\columnwidth}{2.0M}& CE & kw-filler & 5.1 & 0.074 \\
      %\hline
     &\multirow{1}{0.05\columnwidth}{CD}&\multirow{1}{0.05\columnwidth}{0.6M}& CE &  4.0 & 0.051 \\
      %0.015+0.036
      %\cline{2-7}
      %&\multirow{1}{0.05\columnwidth}{CI}&\multirow{1}{0.05\columnwidth}{0.5M}& CE & smooth & 10.2 & - \\
      %\hline \hline
       {TDNN HMM }&\multirow{1}{0.05\columnwidth}{CD}&\multirow{1}{0.05\columnwidth}{0.6M}& CE+sMBR & 3.5 & 0.050
       \\
       %0.015+0.036
       %\cline{2-7}
      &\multirow{1}{0.05\columnwidth}{CI}&\multirow{1}{0.05\columnwidth}{0.5M}& LF-bMMI &  \textbf{2.9} & \textbf{0.028}
       \\
       %0.008+0.020
       %\cline{4-7}
      %&&& NU-LF-bMMI & kw-filler & 2.7 & - \\
       \hline\hline
       \multirow{1}{*}{LSTM CTC}&\multirow{1}{0.05\columnwidth}{CI}&\multirow{1}{0.05\columnwidth}{0.8M}& CTC & \textbf{3.2} & \textbf{0.038} \\
      \hline
    \end{tabular}
  }
\end{table}


\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=\textwidth]{figure/roc.pdf}
    \bicaption[fig:roc]{非固定关键词的关键词检测的ROC 曲线比较}{非固定关键词的关键词检测的ROC 曲线比较}{Fig}{The ROC curve comparison of unrestricted KWS. }
\end{figure}


这里我们使用交叉熵训练得到的系统作为第一行的基线。它是一个基于 NN-HMM 的传统系统，包含了聚类的tri-phone 状态建模。 这里的HMM拓扑结构见图~\ref{fig:hmm-topo}(a)。
传统鉴别性训练在交叉熵系统基础上进行。这里的词图由模型与一元语言模型解码得到~\cite{povey2007evaluation}。
前两行显示传统的词图鉴别性训练改善了 12\%性能，这一结论与LVCSR中类似~\cite{povey2005discriminative}。 在RTF上的轻微改善则是由于更好的声学模型提供了更少的搜索混淆性。

第三行对比第二行显示了所提出的最好的基于HMM的序列鉴别性训练方法与传统鉴别性训练方法的比较。
%Result shows two folds of superiority
这里显示出 17\% 相对改善 ($\alpha = 0.05$, $p = 0.06$, 在显著性检验测试中) 相比传统鉴别性训练和 28\% 相对改善 ($\alpha = 0.05$, $p = 10^{-5}$)  相比交叉熵训练系统。
这来源于更好的在所提出方法中的建模效果:
\begin{itemize}
 \item 如前文所述，修改后的HMM结构和更低的帧率都能带来性能的改善。
 \item KWS模型的LVCSR词图并不包含较好的竞争路径。这些词图来自声学模型与语言模型的共同解码，而KWS的声学模型性能较弱，并不是针对ASR识别进行设计的。因此这些质量更差的词图限制了鉴别性训练所带来的提升。
 \item 传统鉴别性训练在生成词图时候使用的词级别语言模型在KWS的测试阶段并不存在。而LF-MMI中使用的词级别语言模型则是对于测试阶段使用的由词典构成的关键词序列的一个很好的近似。
\end{itemize}
除此之外，与CE基线相比，LF-bMMI 系统取得了一倍的加速，原因在于模型推理搜索和解码搜索都得到了加速。对于前者，主要是由于帧率减少。而后者主要是由于所使用的CI单元比传统CD单元少，使得搜索空间变少，这也包括对filler模型的相应简化。

使用LSTM的CTC系统在最后一行中，也显示了比传统CE模型更好的性能 ($\alpha = 0.05$, $p = 0.01$) 以及比传统鉴别性训练系统更好的性能 ($\alpha = 0.05$, $p = 0.11$)。 从图~\ref{fig:roc}中看, CTC系统存在相对较多误唤醒。

我们在一些初始的尝试中使用基于HMM的序列鉴别性训练作用在CTC初始化的变种模型上~\cite{sak2015fast,nict-icassp17}。但结果并不成功，没有带来改善: 在词级别CTC中~\cite{li2018developing}, LVCSR 解码词图不包含有效的竞争路径 。而在音素级别模型上，如前所述，词图的质量限制了传统框架下鉴别性训练所能得到的改善。% ii) Essentially, after CTC pre-training, the state prior probability $P(\mathbf{L})$~\cite{nict-icassp17} is combined with the original model to form a CTC variant. The CTC variant models $P(\mathbf{O}|\mathbf{L})$, and become a GSM. 

\subsection{中文数据集唤醒词识别}
\label{Sec:exp-wakeup-word-rec}
\subsubsection{实验配置}
\label{Sec:exp-wakeup-word-rec-setup}
%data
%20170321 bj123 定制唤醒词 baseline.txt
本章节进一步测试了在固定关键词的KWS系统中的性能。我们准备了一个类似于文献\cite{chen2014small}和  \cite{cas-icassp17}中介绍的数据集。它包含两部分：通用语音数据和关键词相关数据集。第一部分包含100小时，第二部分包含30K关键词正例，和180K关键词负例。详细的数据集配置可以参见~\cite{chen2018kws}。

%metrics
测试数据包含两部分：关键词相关集合和环境噪声集合。第一部分用于测试模型在区分关键词和非关键词时候的能力\cite{chen2014small}。 它们包含2K正例和10K负例，代表了 20\% 左右的比值，这符合该应用的实际应用场景。前文我们讨论的EER被作为准则。
环境噪声集合则用于测试模型对误唤醒的鲁棒性\cite{cas-icassp17}。它包含300小时的环境噪声。每小时的误唤醒次数记为 {\em{误唤醒频率}} (FAF), 也被作为度量模型性能的指标。
后处理中获取EER的超参数方法如前面章节所述。
每个关键词都单独包含它自己专门的平滑方法的阈值。总体的EER是每个关键词EER的平均值。
之后我们会固定所有的超参数并测试系统在噪声集合中的FAF。

%model 
在该任务中，我们测试了词级系统和音素级系统。HMM和CTC的鉴别性训练系统与传统交叉熵系统进行了比较。词级系统的输出为关键词序列中的每个词，而音素级系统的输出则为中文中的不带调音节。特征和声学模型配置与前面章节一致。
NU-LF-bMMI采用$\alpha=10.0$ 和 $\beta=10.0$。

\subsubsection{实验结果和比较}
\label{Sec:exp-wakeup-word-rec-result}

表~\ref{tab:perf-mandarin}显示了相应的结果。
一个交叉熵训练的词级别的TDNN系统被作为基线系统~\cite{chen2014small}。该系统采用了后验平滑作为后处理方式。

%compare EER \& FAF

\begin{table}[thbp!]
  \caption{\label{tab:perf-mandarin} {\it  固定关键词的KWS系统的性能和速度比较}}
   \vspace{2em}
  %\vspace{1mm}
  \centerline{
    \begin{tabular}{c|m{4.5em}|c|c||ccc}
      \hline
      %&
      %&&& \multicolumn{4}{c}{post-processing} \\
      %\cline{4-7}
      %&
      %&&&  \multicolumn{2}{c}{smooth} & \multicolumn{2}{c}{kw-filler} %& \multicolumn{2}{c}{MED}\\
      %\cline{4-7}
      \multicolumn{1}{c|}{Model}
      &\multicolumn{1}{c|}{Unit} 
      &\multicolumn{1}{c|}{Criterion}&\multicolumn{1}{c||}{Post }&EER&FAF&RTF%&FS&RTF
      \\
      \hline\hline
      %/aifs/users/zhc00/works/kws/lfmmi_chn700/exp/nnet3/chn700.subsetby20_train.nnet_tdnn_a_tiny/
      \cite{chen2014small}
      &\multirow{1}{*}{Word}
      &CE &smooth & 6.2 & 0.64 &0.014\\
      %0.013
     \hline\hline
      %
      \multirow{3}{*}{HMM}&\multirow{3}{*}{Syllable}
      &CE & & 10.2 & 1.40 &0.041\\
      %0.015+0.026
      %\cline{3-7}
      %/aifs/users/zhc00/works/kws/lfmmi_chn700/exp/chain/.tdnn_sjtu_mono_2n_mhmm1c.0.1.128.4_nd.chn700/
      && LF-bMMI &kw-filler &8.3& 1.06 &0.033\\
      %0.008+0.025
      %\cline{3-7}
      %/aifs/users/zhc00/works/kws/lfmmi_chn700/exp/chain/res_a.0.99.tdnn_sjtu_mono_2n_mhmm1c.0.1.128.4_nd.chn700/decode_testset.full.lnovopc_mcsnor_evl17feb_v1_graph_res3/scoring_kaldi/kws.rst2
      %exp/chain/chn700.subsetby5_train.res_a.0.99.tdnn_sjtu_mono_2n_mhmm1c.0.1.128.4_nd.chn700/decode_testset.full.lnovopc_mcsnor_evl17feb_v1_graph_res3/scoring_kaldi/kws.rst2
      && NU-LF-bMMI& & \textbf{5.2} &\textbf{0.51} &\textbf{0.029}\\
      %0.008+0.021
      \hline\hline
      %/aifs/users/zhc00/works/kws/ctc_chn700/ctc
      \multirow{2}{*}{CTC}
      &\multirow{1}{*}{Word}
      & \multirow{2}{*}{CTC} &smooth &9.1 & 1.13 & 0.024  \\
      %\cline{2-2}\cline{4-7}
      %ref: https://spetechcular.com/trac/asr/wiki/ctc_kws_chn_car https://spetechcular.com/trac/asr/wiki/%E6%AF%85%E8%90%8C2016#a2016.6.6
      &\ +{\tt filler}& &MED & \textbf{7.0}&\textbf{0.90} & \textbf{0.029}\\
      %0.024
      \hline
    \end{tabular}
  }
\end{table}

在第二行中，模型也是通过CE准则进行训练的。模型的建模单元是音节，后处理方法为 kw-filler。 
该系统性能在EER和FAF中都有所下降，原因是音素级系统具有更多建模单元。而这些建模单元都被等同地进行训练。与之相反，词级系统则可以对特定关键词具有更强的建模能力。
\cite{chen2014small}中显示了类似结论，这说明后验概率平滑方法的CE模型系统是一个较强的基线系统。

在第三行中，我们所提出的LF-bMMI系统显著改善了CE系统，取得了一致更优的EER和FAF。但是，所得到的系统仍然差于基线系统。为了解决针对关键词区段识别性能差的问题，我们使用了NU-LF-bMMI 方法，在第四行中。结果显示NU-LF-bMMI 系统得到了相对第一行基线中显著更好的结果。我们认为这包括两方面原因：第一，非一致地训练关键词相关的音素序列，理论上等同于对关键词的每个词单元专门进行训练，所以其建模能力类似； 第二，由于音素系统通过所提出的NU-LF-bMMI增强了关键词之间与关键词和非关键词之间的鉴别能力，因此它能够取得更优的性能。关于效率，虽然该系统的模型推理搜索速度较快，但由于引入kw-filler的搜索部分，因此导致两倍的速度减慢。使用标签同步解码算法对系统进行加速是未来一个值得研究的问题。

最终，CTC系统也参与了比较。在第五行中的系统类似于\cite{fernandez2007application}。虽然它在文献\cite{fernandez2007application}中取得了较好的性能, 但在本部分测试中仍然差于词级别的CE系统。我们相信这是因为我们使用的训练和测试集相比该文献具有更大的挑战。我们针对这一系统如前文所述，添加了 $\tt filler$ 建模单元，以改善关键词与非关键词之间的鉴别性；同时我们增加了基于 MED的后处理算法，以便引入音素混淆性的先验知识。我们所提出的系统在第六行中取得了显著更好的结果。但是这个系统仍然没有超过传统的CE系统。
%This may be because the baseline in fixed vocabulary KWS is highly tuned while the CTC-MED approach treats all phones equally during training. It is worth noting that due to the same reason, the LF-bMMI approach does not outperform the baseline neither. 
我们认为进一步的改善应该包括两方面：对CTC模型的噪声鲁棒性的研究；使用更好的深度学习模型来改善模型性能。
%in keyword specific corpus 

%MED uses

\subsection{多说话人重叠语音信号任务}
\label{Sec:exp-pit}

\subsubsection{实验配置}
\label{Sec:exp-pit-setup}

本章节使用300小时 Switchboard 数据集~\cite{godfrey1992switchboard}。测试使用NIST
2000 CTS (hub5e-swb) 测试集的 Switchboard (SWB) 子集。两个说话人的重叠语音是通过人工混叠而后合并得到的（0dB）。文献\cite{chen2018progressive}中描述了混叠的具体过程。经过混叠之后，我们拥有150小时作为训练数据，称为 {\em{150 小时数据集}}, 以及 915 句测试集。通过解码之后，由于每句话有2个说话人，因此我们将得到1830个句子用于最终评估准确率。我们同时取了三分之一的训练数据组成一个更小的集合，称为 {\em{50 小时数据集}}。

在模型训练阶段使用80维 log-filterbank 特征。CNN模型使用41帧作为窗长。模型使用Microsoft Cognitive Toolkit (CNTK)~\cite{seide2016cntk}进行训练。声学模型使用 9000 个triphone绑定状态。所有数据的状态信息是通过在人工混叠之前的干净数据上进行强制对齐而得到的。本章节使用的基线系统类似于文献~\cite{yu2017recognizing}中的联合训练PIT-ASR系统。这个PIT-ASR 模型包含10层双向 LSTM 层，包含768 个模型单元在每个方向中。本章节系统中的语音识别模型包含 4 层双向 LSTM ，每层包含 768 个单元，在干净语料上预训练得到。

%evaluation
在测试阶段，本章节使用30k词表大小的语言模型进行解码，详细配置参见文献~\cite{chen2018progressive} 。在测试中，PIT模型的两个输出分别进行解码，以得到两个说话人分别的转录序列。对于WER的计算，我们分别计算各种两两排列组合底下的WER，并选取更好的那一种组合作为最终的WER~\cite{yu2017recognizing}。我们这里给出了两个输出的平均WER作为最终的WER。
%as firstly they are always shown similar number, and secondly  recognizing both streams of the overlapped speech is the problem focused.

\subsubsection{实验结果和比较}
\label{Sec:exp-pit-result}

表~\ref{tab:exp-combine} 总结了前文所提出的各种改进对性能的影响。

\begin{table}[thbp!]
  \caption{\label{tab:exp-combine} {\it  50 小时数据集上的性能改善总结}}
  %\vspace{1mm}
  \centerline{
    \begin{tabular}{ c m{0.33\columnwidth}||c c}
      \hline
      \multicolumn{1}{c}{深度学习 } &
      \multicolumn{1}{c||}{模型} &
      \multicolumn{1}{c}{WER} &
      \multicolumn{1}{c}{相对改善比 (\%) } \\
      \hline \hline
       10$\cdot$0 BLSTM &  PIT-CE& 57.5& 0 \\
        \hline\hline
        %without teacher
         \multirow{4}*{{6$\cdot$4 BLSTM}} &progressive joint training & 50.2 & -13 \\
        %https://philly/#/jobProgress/rr1/Redmond%20Ridge%201/sdrgvc/cntk-p-f2.transf.togself.ssfb.cnn.pat.cntk.8..clnasr.cntk.100.0.check.dnn.91.application_1498034356001_1450.f2.ssfb2.clnn5.check.dnn.17.50!~!~!8/1498034356001_2261/%5C%5Cstorage.rr1.philly.selfhost.corp.microsoft.com%5Csdrgvc_scratch%5Csys%5Cjobs%5Capplication_1498034356001_2261/false
        &\ \ + clean teacher& 38.9&-32.4 \\
        %running
        %38 rsts/application_1498357370006_0153.lfmmi2.b0.2.PAT.cntk.dnn.28.50.dnn.3.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys  Sum/Avg 1831  21436 64.7  24.9  10.4  2.7 38  68.3  -6.898    "cntk-r-lfmmi2.b0.2.pat.cntk.lr2-8.application_1497925609995_0099.transf.togself.ssfb.50.dnn.28.50!~!~!8    application_1498357370006_0153  \ 0 100.0 Pass"
        %
        % for the small improvement, might come from limitation of the "shared" layer 
        %
        %&\ \ \ \ + LF-DC-bMMI& 38.0 & -34.0 \\
        %35.8 rsts/application_1498589312003_1311.f2.sh.transf.mmi.togself.dnn.65.50.dnn.28.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys Sum/Avg 1831  21436 66.6  22.9  10.5  2.3 35.8  67.8  -6.531    "cntk-r-f2.sh.transf.mmi.togself.ssfb.pat.cntk.8.mi2.pat.cntk.lr.dnn.11.application_1497618360018_0844.ssfb.l5.cntk2.check.dnn.65.50!~!~!8    application_1498589312003_1311  \ 1.6937166 32.0  Running"
        &\ \ + MMI clean teacher&35.8 &-37.7 \\
        %"application_1498589312003_2191" ...
        %35.2 rsts/application_1498589312003_3578.lfmmi2.nb0.2.ceh.PAT.dnn.28.50.dnn.7.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys  Sum/Avg 1831  21436 67.9  23.6  8.5 3.1 35.2  67.4  -6.646    "cntk-r-lfmmi2.nb0.2.ceh.pat.cntk.lr2-8.application_1498589312003_1311.f2.sh.transf.50.dnn.28.50!~!~!8    application_1498589312003_3578  \ 0.1997759 83.0  Running"
        &\ \ \ \ + LF-DC-bMMI& 35.2 &  -38.8 \\
        %some cnn
        %1498589312003_3350
        %1498589312003_3349
        %1498589312003_3348
      \hline\hline
      \multirow{4}*{{1 LACE + 5$\cdot$4 BLSTM}} &progressive joint training & 47.4 & -17.5 \\
      %ce 36  rsts/application_1498589312003_6017.cnn.f5.sh.transf.sep.dnn.88.50.dnn.4.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys  Sum/Avg 1831  21436 65.7  22  12.2  1.7 36  68.9  -6.395    "cntk-p-f5.sh.transf.sep.togself.ssfb.cnn.pat.cntk.8..clnasr.cntk.100.0.check.dnn.91.application_1498589312003_1947.f2.ssfb2.clnn5.check.dnn.88.50!~!~!8    application_1498589312003_6017  \ 1.8234308 5.0 Running"
      &  \ \ + clean teacher& 36.0&-37.4\\ 
      %/msr-hdp-gw0015/Scratch/jdroppo/t-zhehch/decode/rsts/application_1498589312003_5950.cnn.f5.sh.transf.sep.dnn.88.50.dnn.17.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys: | Sum/Avg   | 1831  21436 | 67.5   22.3   10.2    2.4   34.9   68.1 | -6.439 |
      %34.6 rsts/application_1498589312003_5950.cnn.f5.sh.transf.sep.dnn.88.50.dnn.19.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys Sum/Avg 1831  21436 67.6  22.1  10.2  2.3 34.6  68.2  -6.388    "cntk-p-f5.sh.transf.sep.mmi.togself.ssfb.cnn.pat.cntk.8.mi2.pat.cntk.lr.dnn.11.application_1498589312003_1947.f2.ssfb2.clnn5.check.dnn.88.50!~!~!8   application_1498589312003_5950  \ 1.8100199 22.0  Running"
       &\ \ + MMI clean teacher& 34.6 &-39.8\\ 
       %1498589312003_6776
       %1498589312003_6775
       %1498589312003_6774
       %1498589312003_6773
       %34  rsts/application_1498589312003_6878.cnn.cnn.lfmmi2.nb0.3.dnn.19.50.dnn.8.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys  Sum/Avg 1831  21436 69.1  22.6  8.3 3.1 34  66.8  -6.477    "cntk-r-cnn.lfmmi2.nb0.3.pat.cntk.lr2-8.application_1498589312003_5950.f5.sh.transf.50.dnn.19.50!~!~!8    application_1498589312003_6878  \ 0.2240226 75.0  Running"
       &\ \ \ \ + LF-DC-bMMI& 34.0 & -40.9 \\
      \hline
    \end{tabular}
  }
\end{table}

PIT-ASR 模型~\cite{yu2017recognizing}, 表示为 PIT-CE, 被作为联合训练方式的基线系统，在第一行中。 
本文提出的逐步联合训练方法在第二行中，是一个更好的通过分部分微调结合起来得到的联合训练系统。本文提出的基于自迁移学习的联合训练模型显示出了额外的非常显著的性能改善，显示在第三和第四行中。最后，多输出的序列鉴别性训练被进一步应用到上述系统中，并取得了额外的改善，即使教师模型已经是一个基于MMI序列鉴别性准则训练的模型，这与~\cite{7913606}中观察到的现象类似。
图~\ref{fig:example}中给出了一些本文提出的系统所得到的解码例子，以及其相对应的PIT基线系统的例子。基线系统包含了很多模型泛化能力差所带来的错误。通过所提出的方法，错误得到了显著的减少。注意到在这个例子中，本章提出的基于自迁移学习的联合训练方法主要减少了相似发音之间的错误识别，而序列鉴别性训练则主要减少一些明显的语法和语言学错误，这些现象符合我们对两种训练方法的预期，也显示了它们可以被结合在一起。


\begin{figure}[!htp]
  \centering
    \captionstyle{\centering}
    \includegraphics[width=\textwidth]{figure/pit-example.pdf}
    \bicaption[fig:example]{50 小时数据集的解码例子}{50 小时数据集的解码例子，这里比较了所提出的方法与PIT基线的不同性能。上半部分来自A输出，下半部分来自B输出。 C, S, D, I 分别表示：正确，替换错误，删除错误，插入错误。}{Fig}{The decoding examples of 50 hours corpus.}
\end{figure}


另一方面，在相似参数量情况下但使用其他的深度学习模型，即 {1 LACE + 5$\cdot$4 BLSTM}, 这样的系统可以带来一致性的性能改善，显示在第六到第九行中。我们相信这些额外的改善来自对于问题模块化的合理假设，由此对深度学习模型进行了合理的使用。这些相似比较分析可以参见文献~\cite{chen2018progressive}。

%table:
%joint (baseline)
%v.s.
%transfer learning based progressive joint
%v.s.
%transfer learning based progressive joint + disc tr
%v.s.
%disc tr teacher + transfer learning based progressive joint
%v.s.
%disc tr teacher + transfer learning based progressive joint
%+ disc tr

%\subsection{Extension to Large Corpus}

表~\ref{tab:exp-combine-large} 进一步将数据集扩展到150 小时数据集，由此显示了再更多训练数据时候的性能。

\begin{table}[thbp!]
  \caption{\label{tab:exp-combine-large} {\it  150小时数据集上的性能比较}}
  %\vspace{1mm}
  \centerline{
    \begin{tabular}{ c m{0.35\columnwidth}||c c}
      \hline
      \multicolumn{1}{c}{深度学习 } &
      \multicolumn{1}{c||}{模型 } &
      \multicolumn{1}{c}{WER} &
      \multicolumn{1}{c}{相对改善比 (\%) } \\
      \hline \hline
      %150h 42.2  rsts/application_1497046849606_0396.ce.l10.cntk2.PAT.check.dnn.100.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys  Sum/Avg 1831  21436 59.9  24.9  15.2  2.1 42.2  70.9  -7.077
       10$\cdot$0 BLSTM&   PIT-CE& 42.2& 0\\
        \hline\hline
        %application_1497618360018_1496
        %application_1498034356001_0259
       \multirow{3}*{{6$\cdot$4 BLSTM}} &progressive joint training & 41.0& -2.9 \\
        %application_1498034356001_0292
        %running
        %1498034356001_2465
        %1498034356001_2464
        %REDMOND.t-zhehch@GCRGDL106:/msr-hdp-gw0015/Scratch/jdroppo/t-zhehch/decode$ grep -h ^32.8,  csv/* | grep -v mmi | sort -n | uniq
        %32.8,rsts/application_1497925609995_0264.transf.togself.ssfb.PAT.cntk-16.dnn.51.150.dnn.68.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys,Sum/Avg,1831,21436,69.0,19.5,11.5,1.8,32.8,67.8,-5.963,,cntk-p-transf.togself.ssfb.pat.cntk.16..clnasr.cntk.100.0.check.dnn.91.application_1497618360018_0848.ssfb.l5.cntk2.pat.check.dnn.51.150!~!~!16                application_1497925609995_0264  \       0      100.0    Failed
        &\ \ + clean teacher& 32.8& -22.3 \\
        %30.8 rsts/application_1498589312003_1382.lfmmi2.b0.2.PAT.cntk.dnn.68.150.dnn.11.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys  Sum/Avg 1831  21436 71.7  20.1  8.2 2.5 30.8  64.4  -6.007    "cntk-r-lfmmi2.b0.2.pat.cntk.lr2-8.application_1497925609995_0264.transf.togself.ssfb.150.dnn.68.150!~!~!8    application_1498589312003_1382  \ 0.232133  100.0 Pass"
        &\ \ \ \ + LF-DC-bMMI& 30.8 & -27.0 \\ %6\% improve
        %some trials on clnn in 150hrs:
        %1498589312003_2837
        %1498589312003_2836
        \hline\hline
        \multirow{3}*{{1 LACE + 5$\cdot$4 BLSTM}} &   progressive joint training & 39.4 & -6.6 \\
        %rsts/application_1498589312003_6527.cnn.f5.sh.transf.sep.dnn.96.150.dnn.24.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys: | Sum/Avg   | 1831  21436 | 71.1   18.1   10.8    1.6   30.4   66.2 | -5.677 |
        &\ \ + clean teacher& 30.4& -27.9 \\
        %application_1498589312003_7664
        %application_1498589312003_7665
        %application_1498589312003_7666
        %application_1498589312003_7667
        %application_1498589312003_7668
        %application_1498589312003_7669
        %28 rsts/application_1498589312003_8256.cnn.cnn.lfmmi2.nb0.3.dnn.24.150.dnn.11.0_fmix80/ac.0.067/final/rearrange.mlf.ctm.sys  Sum/Avg 1831  21436 74.3  18.4  7.3 2.3 28  63  -5.7    "cntk-r-cnn.lfmmi2.nb0.3.pat.cntk.lr2-8.application_1498589312003_6527.f5.sh.transf.150.dnn.24.150!~!~!8    application_1498589312003_8256  \ 0.2945081 100.0 Pass"
        &\ \ \ \ + LF-DC-bMMI& 28.0 & -33.6 \\ 
      \hline
    \end{tabular}
  }
\end{table}

该表中传统的联合训练基线在第一行中，它相比之前50小时系统显著改善了性能，由此缩短了与逐步联合训练模型在第二行之间的性能差距。但是它仍然显著差于前面表中本文所提出的基于自迁移学习和鉴别性训练的50小时系统。这说明PIT这类模型确实比较受制于模型的复杂度和模型泛化的不充分性。换句话说，为了提升模型的泛化能力，使用更多的数据，不如使用本文所提出的更好的模型训练方法。另一方面，使用更多数据时模型的收敛速度也四倍慢于本文所提出的50小时系统。

比较表~\ref{tab:exp-combine-large} 与表~\ref{tab:exp-combine},  本文所提出的基于自迁移学习的联合训练方法以及鉴别性训练方法都带来了显著的相对改善，相比于上文中的基线系统。相比于表~\ref{tab:exp-combine}, 序列鉴别性训练方法带来了更大的相对性能改善比，相比于传统基于CE准则训练的教师模型的迁移学习系统。

在两个数据集上，本文所提出的的方法都比当前最后的系统提升了相对30\% 。这里的性能改善来自于更好的模型泛化能力，更高的训练效率，和更好地融合序列级的语言学信息。


\section{本章小结}
\label{chap:kws-sum}

本章节提出了基于序列鉴别性训练的深度学习关键词检测模型的训练框架。通过使用音素语言模型或者使用显性添加建模单元的方式，对竞争可能路径进行建模，由此得到更好和更快的序列鉴别性训练。
我们的实验在语料库检索任务和唤醒词识别任务上进行。对于前者，词表大小通常是无限制的，而对于后者，则要求有更强的噪声鲁棒性。相比于传统的逐帧CE深度学习模型在固定关键词和非固定关键词的关键词检测任务上的最好的系统，尽管不同应用具有不同的特征，但是实验显示我们所提出的鉴别性训练方案可以取得一致和显著的改善。
%
另一方面，在多说话人重叠语音信号识别任务中，本章节通过联合优化，迁移学习，序列鉴别性训练等方式，改善了原来语音分离、信号增强和语音识别的联合训练系统，在多个不同大小数据集上显示了一致和非常显著的性能改善。
