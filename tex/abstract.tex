%# -*- coding: utf-8-unix -*-
%%==================================================
%% abstract.tex for SJTU Master Thesis
%%==================================================

\begin{abstract}

语音识别中一个独有并且有趣的自然现象是声学序列和语言学序列的长度可变性，这使得语音识别需要同时建模两种序列之间的状态对齐与模式分类。
%
在训练阶段，一组带有已知标签的输入特征被提供给系统进行模型构建，{\em 序列建模}和{\em 模式分类}是前一问题的两大核心，这决定了语音识别系统可达到的识别精度的上限；而测试阶段，
通常由单帧的分类器推理和逐帧的联合转移模型、字典和语言模型的{\em 搜索解码}组成，这决定了识别速度和实际可达的识别精度。
%
近年来，深度学习模型被引入到语音识别的声学和语言建模当中替代传统分类器，显著改善了模式分类问题的精度。 但基于深度学习的语音识别并没有改变序列建模和搜索解码的本质。
本论文围绕深度学习背景下的序列建模和搜索解码技术展开了一系列探索和研究，
大幅改善了{\em 多种类}语音识别系统的{\em 精度}和{\em 速度}。

第一部分，本论文首次针对关键词检测和多说话人重叠语音信号识别任务提出了{\em 序列鉴别性准则}和训练方案，大幅提升了非传统语音识别任务的{\em 精度}。
%
序列建模方法通常只在训练标准的大词汇连续语音识别（LVCSR）模型时进行使用，但针对其它非传统识别任务的序列建模研究并不充分，这包括：关键词检测任务和多说话人重叠语音信号识别任务等。这类任务仍然是序列预测问题，但是却没有合适的训练准则和相应的设计，来充分优化分类器的序列建模能力。
为了将序列鉴别性训练引入关键词检测任务，核心难题是设计相应的竞争可能性建模方法。本论文提出采用无词图鉴别性训练框架来解决这一问题：隐性使用音素语言模型来建模。
另一方面，单通道多说话人混叠语音识别也属于序列级问题, 
我们提出了一种传统鉴别性训练技术变种，它在进行鉴别性训练的同时，也抑制输出通道上说话人跟踪错误。通过联合优化，迁移学习，序列鉴别性训练等方式，我们显著改善了原来语音分离、信号增强和语音识别的联合训练系统。


第二部分，在解码搜索过程当中，本论文从每帧的搜索速度和整段语音所需搜索的次数两个不同层面提出了新型加速框架，累计对LVCSR任务产生了百倍的{\em 速度}提升：
%解码搜索并行化和降低算法复杂度
\begin{itemize}[leftmargin=2mm]
	\item 针对每帧的搜索速度，本论文提出面向大规模图搜索的{\em 并行维特比搜索算法}，并在GPU上实现开源该套算法。
%
基于GPU的并行计算已广泛应用于神经网络训练和推理加速，但是大规模解码网络（百亿边级别）的并行搜索算法研究仍然是空白。
%
语音识别解码搜索网络中多数边之间并不直接相关，具有并行处理的可能性，但其可重复和独立的计算模式并不显而易见。本论文提出了如下解决方案：
将维特比算法中的令牌合并操作实现为一个GPU并行计算中的原子操作以减少同步消耗；提出了动态负载均衡的方式以提高其多线程之间的利用率；重新设计了基于GPU并行计算的精确的词图生成和剪枝算法。
%
在Switchboard 上实验表明，本论文所提出的方法在取得完全一致的1-best和词图质量情况下，可以得到3-15倍的加速。除此之外，如果再进行多句子的并行处理，最终的加速比将达到46倍。
%所提出的离线解码器对语言模型和声学模型没有特别的限制，并且可以工作在各种架构的GPU上。

	\item 针对整段语音所需搜索的次数，本论文采用具有混淆区段建模（blank单元建模）能力的模型，系统地提出了{\em 标签同步算法}，其通过一系列方法使得搜索解码过程从逐帧同步变为标签同步。
当前主流的推理搜索方法是帧层面的维特比束搜索算法，在每一帧都要进行大规模的解码网络搜索，其算法复杂度很高，限制了语音识别的广泛应用。本论文提出对blank区段完全不进行搜索，将特征层面的搜索过程改变为标签层面，使得解码速率小于特征速率，即不必在每帧上都进行大规模搜索。
%具体来说，在标签搜索阶段，对帧层面声学模型的输出增加一步后处理过程, 得到对每个输出标签概率计算的近似值，再进行标签搜索。
与传统方法相比，该方法的优势是搜索空间更小，且搜索过程被大大加速。
本论文提出的一系列通用方法在隐马尔科夫模型和连接时序分类模型上得到了验证，取得了3-5倍的大幅加速。
\end{itemize}

第三部分，本论文进一步探讨标签同步解码算法的一些扩展应用，改善了它们的精度和速度。
上述标签同步算法所带来的搜索误差显著减小，由此产生高质量的音素词图，具有准确和紧致的特点，称为{\em LSD音素词图}。我们将这种高精度词图应用于{\em 关键词检测}，多识别任务统一{\em 置信度}框架，以及{\em 端到端语音识别}。
%
在关键词检测中，我们提出了一套基于编辑距离的LSD音素词图后处理算法以引入混淆性建模，改善了系统精度。
%
在高质量的LSD音素词图基础上，本论文进一步提出了两种置信度生成算法。
%
基于大幅加速的标签同步解码算法，本论文还提出了辅助归一化搜索空间的概念，并尝试使用这样的搜索空间来建模所有语音识别应用领域的置信度。 % and CM can be obtained in an unified framework
%而针对这样做在低功耗设备上带来的挑战，本论文采用标签同步解码来进行处理，由此带来了很大的效率改善。
%最终这一统一高效的置信度框架被应用于目前主流的多种ASR应用。
%
同时本论文还研究了将标签同步算法应用于直接建模输出序列形态学组合的端到端模型的方案。本论文使用模块化训练的思想来改善端到端模型建模，使其更易于使用外在知识源来训练每一个端到端模型的子模块，最终带来更好的精度和速度。
%值得注意的是，模型最后需要进行联合优化，因此最终在推理搜索阶段，模型仍然工作在端到端模式下。



总而言之，本论文围绕深度学习背景下的序列建模和解码搜索技术展开了一系列探索和研究。本论文提出的并行解码搜索技术与标签同步解码算法相结合，可以得到一个极大幅的速度提升；
再结合所提出的通用推理搜索和置信度方案，将得到一个低功耗、高性能的通用语音识别系统。本论文不仅在主要数据集上验证了相关算法，并且开源了部分算法系统。

\keywords{语音识别，序列建模，搜索解码，并行计算，标签同步解码，置信度，序列鉴别性训练}
\end{abstract}

\begin{englishabstract}

A unique phenomenon in human speech is the variable lengths in acoustic waves and linguistic words. Hence {\em automatic speech recognition} (ASR) requires both pattern classification and  state alignment modeling between input and output sequences, called {\em sequence prediction} problem. In the training stage, the model takes  acoustic features as the input and its labeling as the output, where {\em sequence modeling} and {\em pattern classification} are two keys, which determine the upper bound of a speech recognizer. In the inference stage, a speech recognizer is to find a sequence of labels whose corresponding acoustic and language models best match the input feature, called {decoding}, which determines the recognition speed and precision in real application. 
The most recent milestone of ASR is the application of deep neural networks (DNN) in acoustic and language modeling.
However, those successful applications are still based on the traditional formulation of speech recognition and only aim to improve the pattern classification above. In this thesis, the remaining sequence modeling and decoding problems are systematically investigated in the modern DNN based ASR.

We propose sequence modeling solutions of unconventional ASR tasks, keyword spotting (KWS) and overlapped speech recognition,  for the first time. Traditional sequence modeling research is usually conducted on the acoustic modeling of conventional speech recognition systems. Although keyword spotting and overlapped speech recognition are both inherently sequence prediction problems, they have not benefited from sequence modeling due to the lack of proper criteria and the difficulties of getting alternative sequence hypotheses for discriminative training. We propose to solve these problems in the lattice-free discriminative training framework. Namely, the competing hypotheses are efficiently modeled by phoneme or sub-word level language models. Moreover, this framework takes  speaker tracing and speech separation errors in overlapped speech into account. 
We propose a specific discriminative training formulation for overlapped speech recognition which also penalizes competing outputs from the overlapped speech. Our sequence modeling solutions achieve significant improvements in both unconventional ASR tasks, and show the potential to be combined with transfer learning and joint training.

For decoding, we propose algorithm speedups in two folds: parallelizing Viterbi search algorithm and decreasing algorithm complexity by label synchronous decoding. Firstly, we propose the {\em parallel Viterbi search algorithm}, implement it in GPU and make it open-sourced, achieving great speedups. Since most of the weighted finite state transducers (WFSTs) arcs in ASR are independent with each other, the search algorithm has the potential to be parallelized. However, the algorithm and implementation naturally work in serial and the previous rare trials have many limitations. We propose a series of solutions and redesign the algorithm:  token recombination as an atomic GPU operation in order to reduce synchronization overheads; dynamic load balancing strategy for more efficient token passing scheduling among GPU threads; the redesign of exact lattice
generation and lattice pruning algorithms for better GPU utilization. Experiments on the switchboard corpus show that the proposed method achieves identical ASR precision, while running 3 to 15 times faster. Additionally we obtain a 46-fold speedup with sequence parallelism and multi-process service (MPS) in GPU.

Secondly, based on confusion $\tt blank$ symbol modeling, we systematically propose {\em label synchronous decoding} (LSD) to transform the search process from frame level to label level and obtain significant speedups. The dominant decoding method nowadays is frame synchronous Viterbi beam search whose algorithm complexity is linear with the length of the acoustic waves. We propose  to transform the search process above from frame level to label level whose complexity is linear with the length of linguistic words. Namely, we utilize effective $\tt blank$ structure and apply efficient post-processing of $\tt blank$ during inference before doing Viterbi search. The proposed framework can be applied to both generative and discriminative sequence models. Experiments on the switchboard corpus show 2-4 times speedup in search without performance deterioration.

Moreover, significantly better quality of phone and word level lattices can be obtained from LSD methods above, called {\em LSD lattices}. We further improve a series of ASR systems based on LSD lattices, including keyword spotting, unified confidence measure framework, and acoustic-to-word (A2W) end-to-end modeling. In KWS, we introduce phoneme level confusion in inference stage by an efficient minimum edit distance  post-processing upon CTC lattices, to improve the precision and robustness. We propose two distinct confidence measure algorithms based on CTC lattices, showing prevalent quality. We propose auxiliary normalization graph upon CTC lattices  and take it as a unified search space for confidence measures in variant ASR applications. We utilize modular training to improve A2W modeling and make it better to utilize external knowledge sources. A LSD based joint training strategy is proposed to obtain better modeling precision and faster inference speed.

In conclusion, this thesis successfully improve the sequence modeling and decoding frameworks in the modern DNN based ASR. Tremendous speedups upon current speech recognizers can be obtained by combining the proposed parallel Viterbi search algorithm and label synchronous decoding. A low power-consumption and high quality unified ASR system can be built upon our works in sequence training and inference framework. The system is verified in variant datasets and some algorithms in the system are open-sourced.

\englishkeywords{\large Speech Recognition, Sequence Modeling, Decoding, Parallel Computing, Label Synchronous Decoding, Confidence, Sequence Discriminative Training}
\end{englishabstract}

